{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOpiH28DbWZ87vjm1Ef3Jw7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olhaau/fl-official-statistics-addon/blob/main/_dev/03_insurance_federated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Insurance - a Federated Learning Use Case.\n",
        "\n",
        "This notebook contains Federated Learning.\n",
        "\n",
        "-- **tba** --"
      ],
      "metadata": {
        "id": "Z1N2mtyx2Uxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "---"
      ],
      "metadata": {
        "id": "2qdJnO4M7VDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pull Repo"
      ],
      "metadata": {
        "id": "aZQgDGzbd3pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# rm repo from gdrive\n",
        "if os.path.exists(\"fl-official-statistics-addon\"):\n",
        "  %rm -r fl-official-statistics-addon\n",
        "\n",
        "# clone\n",
        "!git clone https://github.com/Olhaau/fl-official-statistics-addon\n",
        "%cd fl-official-statistics-addon\n",
        "\n",
        "# pull (the currenct version of the repo)\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5qBP638d0iR",
        "outputId": "8066ebff-16a5-4d22-9359-3097894f4cc2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fl-official-statistics-addon'...\n",
            "remote: Enumerating objects: 696, done.\u001b[K\n",
            "remote: Counting objects: 100% (332/332), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 696 (delta 162), reused 287 (delta 133), pack-reused 364\u001b[K\n",
            "Receiving objects: 100% (696/696), 32.40 MiB | 4.94 MiB/s, done.\n",
            "Resolving deltas: 100% (285/285), done.\n",
            "Updating files: 100% (275/275), done.\n",
            "/content/fl-official-statistics-addon\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installs"
      ],
      "metadata": {
        "id": "1d5TMrK67Xxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  !pip install --quiet nest_asyncio\n",
        "  !pip install --quiet tensorflow_federated\n",
        "  !pip install --quiet tensorflow_addons"
      ],
      "metadata": {
        "id": "UQSYlSd47WaM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "nUcRlUPV7bZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "from tensorflow_addons.metrics import RSquare\n",
        "import tensorflow_addons as tfa\n",
        "import nest_asyncio\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "2zMmbNFf7Wc6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ingest and Split the Data"
      ],
      "metadata": {
        "id": "XxFNFscq8O74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"output/data/insurance-clean.csv\", index_col = 0)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C9zyHqiN9fCo",
        "outputId": "9fbc2b08-2124-47b7-d322-af1b74aedd56"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  sex       bmi  children  smoker     region      charges  region0  \\\n",
              "0  0.021739  0.0  0.321227       0.0     1.0  southwest  16884.92400      0.0   \n",
              "1  0.000000  1.0  0.479150       0.2     0.0  southeast   1725.55230      0.0   \n",
              "2  0.217391  1.0  0.458434       0.6     0.0  southeast   4449.46200      0.0   \n",
              "3  0.326087  1.0  0.181464       0.0     0.0  northwest  21984.47061      0.0   \n",
              "4  0.304348  1.0  0.347592       0.0     0.0  northwest   3866.85520      0.0   \n",
              "\n",
              "   region1  region2  region3  \n",
              "0      0.0      0.0      1.0  \n",
              "1      0.0      1.0      0.0  \n",
              "2      0.0      1.0      0.0  \n",
              "3      1.0      0.0      0.0  \n",
              "4      1.0      0.0      0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae933620-7f36-4212-a44d-a1a3c56c644c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "      <th>region0</th>\n",
              "      <th>region1</th>\n",
              "      <th>region2</th>\n",
              "      <th>region3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.321227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.479150</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.458434</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.326087</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.181464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.347592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae933620-7f36-4212-a44d-a1a3c56c644c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae933620-7f36-4212-a44d-a1a3c56c644c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae933620-7f36-4212-a44d-a1a3c56c644c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 4\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 10\n",
        "SHUFFLE_BUFFER = 20\n",
        "PREFETCH_BUFFER = 5\n",
        "NUM_ROUNDS = 150\n",
        "RUN_NAME = f'0,8-3({NUM_ROUNDS})-{NUM_EPOCHS}-epochs-{BATCH_SIZE}-batch-WithRegion/'"
      ],
      "metadata": {
        "id": "Qam6babo7Wgg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syn_samples_per_region = 1000\n",
        "\n",
        "def get_dataset_for_region(dataset, region_index, test_size_per_region=20):\n",
        "    \"\"\"Min-max scale and return data for a single, given region. The scaler must be fitted before.\n",
        "\n",
        "    :param dataset: The dataset to get the regional data from\n",
        "    :type dataset: pandas.DataFrame\n",
        "    :param region_index: The index number of the region to return\n",
        "    :type region_index: int\n",
        "    :param test_size_per_region: The amount of values to separate for testing, default are 20\n",
        "    :type test_size_per_region: int, optional\n",
        "    :return: The dataset specific for the defined region, the test values, the test labels\n",
        "    :rtype: tensorflow.python.data.ops.dataset_ops.PrefetchDataset, tuple of pandas.core.series.Series\n",
        "    \"\"\"\n",
        "    region_ds = dataset[dataset['region'] == region_index]\n",
        "    region_ds = region_ds.drop(columns=['region'])\n",
        "    len = region_ds.shape[0]\n",
        "\n",
        "    # The scaling into [0, 1] is not necessary anymore, it happens when the data loads already\n",
        "    # region_ds[['age', 'bmi', 'children']] = scaler.transform(region_ds[['age', 'bmi', 'children']])\n",
        "\n",
        "    X_test = region_ds.head(test_size_per_region)\n",
        "    y_test = X_test.pop('charges')\n",
        "\n",
        "    X_train = region_ds.tail(len - test_size_per_region)\n",
        "    y_train = X_train.pop('charges')\n",
        "\n",
        "    fed_train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
        "\n",
        "    return (\n",
        "        fed_train_dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER),\n",
        "        (X_test, y_test)\n",
        "    )"
      ],
      "metadata": {
        "id": "JTutbOjq8VzQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test and train sets and put them into random_client_ds, use four clients which are independent of the region\n",
        "def get_dataset_random_region(dataset, num_clients=4, test_size_per_region=20):\n",
        "    \"\"\"Creates a list with client datasets independent of the region.\n",
        "\n",
        "    :param dataset: The dataset to get the regional data from\n",
        "    :type dataset: pandas.DataFrame\n",
        "    :param num_clients: the number of clients create (equal big datasets per client), default value is 4 clients\n",
        "    :type num_clients: int, optional\n",
        "    :param test_size_per_region: The amount of values to separate for testing, default are 20\n",
        "    :type test_size_per_region: int, optional\n",
        "    :return: List of the prepared dataset with one entry per region, the test values and labels for each region\n",
        "    :rtype: List of (tensorflow.python.data.ops.dataset_ops.PrefetchDataset, tuple of pandas.core.series.Series)\"\"\"\n",
        "    size_of_client_ds = int(dataset.shape[0] / num_clients)\n",
        "\n",
        "    dataset_to_split = dataset.copy()\n",
        "    dataset_to_split.pop(\"region\")\n",
        "    random_client_ds = []\n",
        "    for i in range(num_clients):\n",
        "        sampled = dataset_to_split.sample(n=size_of_client_ds)\n",
        "        dataset_to_split.drop(sampled.index)\n",
        "\n",
        "        X_test = sampled.head(test_size_per_region)\n",
        "        y_test = X_test.pop('charges')\n",
        "\n",
        "        X_train = sampled.tail(size_of_client_ds - test_size_per_region)\n",
        "        y_train = X_train.pop('charges')\n",
        "\n",
        "        fed_train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
        "\n",
        "        train_set = fed_train_dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER)\n",
        "        test_set = (X_test, y_test)\n",
        "\n",
        "        random_client_ds.append((train_set, test_set))\n",
        "\n",
        "    return random_client_ds"
      ],
      "metadata": {
        "id": "8FEwLlGv8eq3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for clients with regional data (each client one region)\n",
        "test_size_per_region = 20\n",
        "regions = ['region0', 'region1', 'region2', 'region3']\n",
        "\n",
        "federated_insurance_data = [\n",
        "    get_dataset_for_region(df.drop(regions, axis=1), i, test_size_per_region=test_size_per_region)\n",
        "    for i in range(NUM_CLIENTS-1)]\n",
        "federated_insurance_data"
      ],
      "metadata": {
        "id": "Dirvrz6Y9ARK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9d544c-2b97-42f1-c30d-c7cb60f4e8c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
              "  (Empty DataFrame\n",
              "   Columns: [age, sex, bmi, children, smoker]\n",
              "   Index: [], Series([], Name: charges, dtype: float64))),\n",
              " (<PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
              "  (Empty DataFrame\n",
              "   Columns: [age, sex, bmi, children, smoker]\n",
              "   Index: [], Series([], Name: charges, dtype: float64))),\n",
              " (<PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
              "  (Empty DataFrame\n",
              "   Columns: [age, sex, bmi, children, smoker]\n",
              "   Index: [], Series([], Name: charges, dtype: float64)))]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for clients with regional independent data\n",
        "random_client_ds = get_dataset_random_region(df, num_clients=NUM_CLIENTS, test_size_per_region=test_size_per_region)"
      ],
      "metadata": {
        "id": "mX6HRriR9Cil"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Tests"
      ],
      "metadata": {
        "id": "RiNQ6m66A7sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"splitted datasets: {}\".format(len(federated_insurance_data)))\n",
        "print(\"------------------------------\")\n",
        "# Q: why range(NUM_CLIENTS-1) and, thus, only 3 clients?\n",
        "\n",
        "# Q: how to output? -> does not work or nothing in it?\n",
        "# -> i think its empty\n",
        "list(federated_insurance_data[0][0].as_numpy_iterator())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRbSvR-Q9058",
        "outputId": "481b1bf9-0b9c-4a75-8482-dc0525bc16c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "splitted datasets: 3\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Show Tensor"
      ],
      "metadata": {
        "id": "GJY8_tVdCXrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Tensor Object\n",
        "X_train = df.iloc[:,0:4]\n",
        "y_train = df['charges']\n",
        "df2 = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFohPc1rAqVw",
        "outputId": "0ef2d47c-789e-4a40-b973-257b481bd722"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=(TensorSpec(shape=(4,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Tensor Object\n",
        "# S. https://stackoverflow.com/questions/62436302/extract-target-from-tensorflow-prefetchdataset\n",
        "list(df2.as_numpy_iterator())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpW57hM4DOBI",
        "outputId": "52db0c83-c7f8-4430-d372-1059ccdd9ed5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([0.02173913, 0.        , 0.3212268 , 0.        ]), 16884.924),\n",
              " (array([0.        , 1.        , 0.47914985, 0.2       ]), 1725.5523),\n",
              " (array([0.2173913 , 1.        , 0.45843422, 0.6       ]), 4449.462),\n",
              " (array([0.32608696, 1.        , 0.18146355, 0.        ]), 21984.47061),\n",
              " (array([0.30434783, 1.        , 0.34759214, 0.        ]), 3866.8552),\n",
              " (array([0.2826087 , 0.        , 0.26311542, 0.        ]), 3756.6216),\n",
              " (array([0.60869565, 0.        , 0.47027172, 0.2       ]), 8240.5896),\n",
              " (array([0.41304348, 0.        , 0.31692225, 0.6       ]), 7281.5056),\n",
              " (array([0.41304348, 1.        , 0.37315039, 0.4       ]), 6406.4107),\n",
              " (array([0.91304348, 0.        , 0.26580576, 0.        ]), 28923.13692)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fx5SFZNkDptQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Builder"
      ],
      "metadata": {
        "id": "2PvPyDQL8iXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_keras_model(\n",
        "    input_features = 9,\n",
        "    initializer = 'zeros',\n",
        "    units = [16,6,1],\n",
        "    activation = None\n",
        "    ):\n",
        "    \"\"\"Create neural network for given number of input features)\n",
        "\n",
        "    :param input_features: The dimension of the first layer with represents the amount of features used\n",
        "    :type input_features: int, optional\n",
        "    :return: Created but not compiled model\n",
        "    :rtype: keras.Model\n",
        "    \"\"\"\n",
        "    return tf.keras.models.Sequential([\n",
        "        # without region: tf.keras.layers.InputLayer(input_shape=(5,)),\n",
        "        tf.keras.layers.InputLayer(input_shape=(input_features,)),\n",
        "        tf.keras.layers.Dense(units[0], kernel_initializer=initializer, activation = activation\n",
        "                              ),\n",
        "        tf.keras.layers.Dense(units[1], kernel_initializer=initializer, activation = activation\n",
        "                              ),\n",
        "        tf.keras.layers.Dense(units[2], kernel_initializer=initializer)\n",
        "    ])\n",
        "\n",
        "\n",
        "# A helper function for federated learning\n",
        "def model_fn(    \n",
        "    input_features = 9,\n",
        "    initializer = 'zeros',\n",
        "    units = [16,6,1],\n",
        "    activation = None):\n",
        "    \"\"\"A function for TFF to create a local model during federated learning and return it as the correct type.\n",
        "    This model uses 9 input features i.e. the regions are part of the features.\n",
        "\n",
        "    :return: The LSTM model to be used as federated models\n",
        "    :rtype: tff.learning.Model\n",
        "    \"\"\"\n",
        "    # We _must_ create a new model here, and _not_ capture it from an external\n",
        "    # scope. TFF will call this within different graph contexts.\n",
        "    keras_model = create_keras_model(\n",
        "            input_features = input_features,\n",
        "            initializer = initializer,\n",
        "            activation = activation,\n",
        "            units = units\n",
        "    )\n",
        "    return tff.learning.from_keras_model(\n",
        "        keras_model,\n",
        "        # without region: \n",
        "        #input_spec = federated_insurance_data[0][0].element_spec,\n",
        "        input_spec = random_client_ds[0][0].element_spec,\n",
        "        loss = tf.keras.losses.MeanAbsoluteError(),\n",
        "        metrics = [tf.keras.metrics.MeanAbsoluteError()\n",
        "        #,tfa.metrics.RSquare()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# Helper functions for different features as input\n",
        "def model_fn_5():\n",
        "    return model_fn(5)\n",
        "\n",
        "def model_fn_5_mod():\n",
        "  return model_fn(5, initializer = 'glorot_uniform', activation = 'relu')\n",
        "\n",
        "def model_fn_9():\n",
        "  return model_fn(9)\n",
        "\n",
        "def model_fn_9_mod():\n",
        "  return model_fn(9, initializer = 'glorot_uniform', activation = 'relu')"
      ],
      "metadata": {
        "id": "9Csom8dD8hRK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Federated Learning"
      ],
      "metadata": {
        "id": "6Sc8xDdk2RTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original Model"
      ],
      "metadata": {
        "id": "_GGvMq3ATosV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Learning Process"
      ],
      "metadata": {
        "id": "GgodbIMsH2b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create iterative learning process which will perform the federated learning\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn_9,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.8),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=3))"
      ],
      "metadata": {
        "id": "K3k21nSQ9P-D"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The initial setup of the learning process\n",
        "print(iterative_process.initialize.type_signature.formatted_representation())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBMUBG1tHFfC",
        "outputId": "2d7c9dd3-9668-4f61-bd46-937ff749917e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "( -> <\n",
            "  global_model_weights=<\n",
            "    trainable=<\n",
            "      float32[9,16],\n",
            "      float32[16],\n",
            "      float32[16,6],\n",
            "      float32[6],\n",
            "      float32[6,1],\n",
            "      float32[1]\n",
            "    >,\n",
            "    non_trainable=<>\n",
            "  >,\n",
            "  distributor=<>,\n",
            "  client_work=<>,\n",
            "  aggregator=<\n",
            "    value_sum_process=<>,\n",
            "    weight_sum_process=<>\n",
            "  >,\n",
            "  finalizer=<\n",
            "    int64,\n",
            "    float32[9,16],\n",
            "    float32[16],\n",
            "    float32[16,6],\n",
            "    float32[6],\n",
            "    float32[6,1],\n",
            "    float32[1]\n",
            "  >\n",
            ">@SERVER)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "1A-Lx1oGH9Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = iterative_process.initialize()"
      ],
      "metadata": {
        "id": "kuAoyOYNbyr5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the federated model with random clients\n",
        "for round_num in tqdm.tqdm(range(1, NUM_ROUNDS)):\n",
        "    result = iterative_process.next(state, [f[0] for f in random_client_ds])\n",
        "    state = result.state\n",
        "    metrics = result.metrics\n",
        "    for name, value in metrics['client_work']['train'].items():\n",
        "        tf.summary.scalar(name, value, step=round_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSqO7EPIHQXJ",
        "outputId": "f51ba4a9-6cea-4e68-91bd-904c230f6eed"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:09<00:00,  1.11s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Kpx2vpWhQY",
        "outputId": "aaa52c08-1817-4d5d-c867-5b30fecf3de6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work',\n",
              "              OrderedDict([('train',\n",
              "                            OrderedDict([('mean_absolute_error', 11003.576),\n",
              "                                         ('loss', 11003.577),\n",
              "                                         ('num_examples', 6280),\n",
              "                                         ('num_batches', 628)]))])),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', OrderedDict([('update_non_finite', 0)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.state\n",
        "# all weights are zero\n",
        "# -> nothing is learned "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhYfnkG4T1qf",
        "outputId": "69a76d94-e24d-443a-8387-2152793542b3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32), array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([0., 0., 0., 0., 0., 0.], dtype=float32), array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32), array([3058.2095], dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=ListWrapper([9, array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32), array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([-0., -0., -0., -0., -0., -0.], dtype=float32), array([[-0.],\n",
              "       [-0.],\n",
              "       [-0.],\n",
              "       [-0.],\n",
              "       [-0.],\n",
              "       [-0.]], dtype=float32), array([269.3884], dtype=float32)]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate"
      ],
      "metadata": {
        "id": "eqkadG5nH_KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the test data for model evaluation\n",
        "X_test = pd.concat([f[1][0] for f in random_client_ds])\n",
        "y_test = pd.concat([f[1][1] for f in random_client_ds])\n",
        "\n",
        "test_sets = [tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.convert_to_tensor(np.expand_dims(el[1][0], axis=0)), \n",
        "    tf.convert_to_tensor(np.expand_dims(el[1][1], axis=0)))) \n",
        "    for el in random_client_ds]"
      ],
      "metadata": {
        "id": "XwZd8b3FHjuh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "evaluation = tff.learning.build_federated_evaluation(model_fn_9)\n",
        "# print(evaluation.type_signature.formatted_representation())\n",
        "model_weights = iterative_process.get_model_weights(state)\n",
        "train_metrics = evaluation(model_weights, test_sets)\n",
        "train_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl-0NiBSJDuO",
        "outputId": "10728282-5ca5-4cd0-9e33-e09d1436c1d7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-552d4a23315f>:2: DeprecationWarning: `tff.learning.build_federated_evaluation` is deprecated, use `tff.learning.algorithms.build_fed_eval` instead.\n",
            "  evaluation = tff.learning.build_federated_evaluation(model_fn_9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('eval',\n",
              "              OrderedDict([('mean_absolute_error', 10782.501),\n",
              "                           ('loss', 10782.502),\n",
              "                           ('num_examples', 80),\n",
              "                           ('num_batches', 4)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model from training results and evaluate\n",
        "model = create_keras_model(input_features = 9)\n",
        "model_weights.assign_weights_to(model)\n",
        "model.compile(\n",
        "    loss=tf.losses.mae,\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    metrics=[\"mae\", 'mean_squared_error']\n",
        ")\n",
        "# The evaluation results, for technical reasons the metrics_names is called afterwards. However, its order fits to the results\n",
        "print(model.evaluate(X_test, y_test))\n",
        "print(model.metrics_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHtfuogKJe6z",
        "outputId": "937afb17-c9b5-45b0-f9b5-c92b9d72246c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 8ms/step - loss: 10782.5020 - mae: 10782.5020 - mean_squared_error: 264664192.0000\n",
            "[10782.501953125, 10782.501953125, 264664192.0]\n",
            "['loss', 'mae', 'mean_squared_error']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test New Learner"
      ],
      "metadata": {
        "id": "J-5ZQ6AyUpyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Learning Process"
      ],
      "metadata": {
        "id": "dLjpPo1sU3A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create iterative learning process which will perform the federated learning\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn_9_mod,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=.05))"
      ],
      "metadata": {
        "id": "FdUZhFGBUv6z"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The initial setup of the learning process\n",
        "print(iterative_process.initialize.type_signature.formatted_representation())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb6cf22-8411-45cb-a8cc-aa987b565916",
        "id": "KNmoEYFdUv61"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "( -> <\n",
            "  global_model_weights=<\n",
            "    trainable=<\n",
            "      float32[5,16],\n",
            "      float32[16],\n",
            "      float32[16,6],\n",
            "      float32[6],\n",
            "      float32[6,1],\n",
            "      float32[1]\n",
            "    >,\n",
            "    non_trainable=<>\n",
            "  >,\n",
            "  distributor=<>,\n",
            "  client_work=<>,\n",
            "  aggregator=<\n",
            "    value_sum_process=<>,\n",
            "    weight_sum_process=<>\n",
            "  >,\n",
            "  finalizer=<\n",
            "    int64,\n",
            "    float32[5,16],\n",
            "    float32[16],\n",
            "    float32[16,6],\n",
            "    float32[6],\n",
            "    float32[6,1],\n",
            "    float32[1]\n",
            "  >\n",
            ">@SERVER)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "1Q8XzfXlU5q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = iterative_process.initialize()"
      ],
      "metadata": {
        "id": "ROyd0BlXb2xr"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the federated model with random clients\n",
        "for round_num in tqdm.tqdm(range(1, NUM_ROUNDS)):\n",
        "    result = iterative_process.next(state, [f[0] for f in random_client_ds])\n",
        "    state = result.state\n",
        "    metrics = result.metrics\n",
        "    for name, value in metrics['client_work']['train'].items():\n",
        "        tf.summary.scalar(name, value, step=round_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c455e9df-2b75-4a01-bcce-e4ce1e681906",
        "id": "lEUgryWFU5q6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149/149 [01:43<00:00,  1.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TwFehjaXOGp",
        "outputId": "22d4a618-c072-4bc9-c7e0-f866eff97cbd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work',\n",
              "              OrderedDict([('train',\n",
              "                            OrderedDict([('mean_absolute_error', 3807.3447),\n",
              "                                         ('loss', 3807.3452),\n",
              "                                         ('num_examples', 6280),\n",
              "                                         ('num_batches', 628)]))])),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', OrderedDict([('update_non_finite', 0)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.state\n",
        "# all weights are zero\n",
        "# -> nothing is learned "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee81f99d-c777-4625-9ef8-2fd71abbcdc3",
        "id": "x3opn587U5q8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 1.0314033e+00,  3.9661708e+00, -1.6035627e-01, -5.5738455e-01,\n",
              "        -3.3340264e-02,  7.6503474e-01,  8.2155237e+00,  3.8735539e-01,\n",
              "         2.7853245e+01,  2.8849010e+01,  2.9533479e-01, -1.5679827e-01,\n",
              "         1.0196646e+00,  3.4656518e+00,  2.4119183e+01,  8.1142206e+00],\n",
              "       [ 7.5573564e-01, -1.2467850e+00, -3.1156147e-01, -8.0819167e-03,\n",
              "        -5.8784224e-02,  6.8030429e-01,  3.4803073e+00,  6.5711129e-01,\n",
              "        -2.1786277e+00, -1.7087191e+00,  3.9536785e-02, -2.1266997e-01,\n",
              "         1.0941437e+00, -8.0068648e-01,  2.8550303e+00, -1.4876491e+00],\n",
              "       [-1.1061091e+00,  1.5479072e+00,  3.0361131e-01,  1.4527263e-01,\n",
              "         7.6374221e+00,  2.7178215e+01,  2.9054230e-01,  2.8993628e+01,\n",
              "         6.8207771e-02,  3.5428636e+00,  3.3488023e+00, -1.3137506e+00,\n",
              "         4.1254173e+01, -1.4898837e-02,  5.9636884e+00, -4.1989894e+00],\n",
              "       [ 1.3273600e+00,  6.9692177e-01,  5.4167647e-02, -5.5476022e-01,\n",
              "        -1.2242582e+00, -2.6644659e-01, -8.3746690e-01, -5.4070824e-01,\n",
              "         1.4568372e+01, -4.1310596e+00, -5.4156816e-01, -3.3306196e-01,\n",
              "        -6.2379569e-01,  2.6726489e+00, -7.8412890e+00,  7.1804657e+00],\n",
              "       [-1.0647225e+00, -8.0918765e-01, -2.9251676e-02,  1.7492387e-01,\n",
              "         5.2531743e+00,  2.8213566e+01,  2.7351689e-01,  2.9770515e+01,\n",
              "        -6.6039457e+00,  5.6818852e+00,  3.0004351e+00,  7.5698686e-01,\n",
              "         4.2627300e+01, -6.5321869e-01,  5.6591649e+00,  2.5229642e-01],\n",
              "       [-1.7652669e+00,  7.3034310e+00, -2.5043953e-02, -1.4480361e-01,\n",
              "        -1.3758433e+00, -4.0325942e+00, -7.0281321e-01, -4.2371802e+00,\n",
              "         2.7615759e+00, -2.1540020e+00, -5.9063315e-01,  1.0978537e-02,\n",
              "        -6.4198980e+00, -3.2975295e+00, -3.3029463e+00, -8.0793409e+00],\n",
              "       [-3.6747587e-01, -6.1422315e+00, -2.3679661e-02,  3.6685643e-01,\n",
              "        -2.0179071e+00, -5.4743943e+00, -1.6082864e+00, -5.9242229e+00,\n",
              "        -2.3660865e+00, -2.8296158e+00, -1.3998438e+00,  9.1646969e-02,\n",
              "        -8.6075201e+00,  7.8365698e+00, -6.3366690e+00,  5.3675227e+00],\n",
              "       [ 6.5494102e-01, -6.2088537e+00, -2.8918758e-01, -1.4130510e-01,\n",
              "        -1.3720174e+00, -5.4040704e+00,  1.4741442e-01, -5.9591889e+00,\n",
              "        -2.7517302e+00, -2.4319968e+00, -4.8183724e-01,  2.5813637e-02,\n",
              "        -8.5351934e+00, -2.9366019e+00, -1.6291307e+00,  8.7015963e+00],\n",
              "       [ 1.5491670e+00,  5.7903242e+00, -3.7223402e-01,  7.3889658e-02,\n",
              "        -8.6840045e-01, -2.7633085e+00, -1.8512592e+00, -3.1056619e+00,\n",
              "        -5.2323395e-01, -3.7554672e+00, -4.1215706e-01, -2.3306714e-01,\n",
              "        -4.5197549e+00, -3.3457212e+00,  1.4914297e-01, -7.8373594e+00]],\n",
              "      dtype=float32), array([ -0.39658362,   1.3323036 ,  -0.1749945 ,  -0.17248094,\n",
              "        -4.944066  , -18.381672  ,  -3.7822762 , -19.11623   ,\n",
              "        -2.9173634 , -12.307355  ,  -2.5330873 ,   0.08329192,\n",
              "       -27.586731  ,  -1.8664949 , -10.796182  ,  -1.3881837 ],\n",
              "      dtype=float32), array([[-2.16119766e-01, -1.48887873e-01,  1.15997806e-01,\n",
              "         2.69319624e-01, -4.54167455e-01,  1.04988015e+00],\n",
              "       [-3.90860051e-01, -3.90359461e-01, -3.98642302e-01,\n",
              "         3.44498563e+00, -3.04647684e-01,  5.91972208e+00],\n",
              "       [-1.83291540e-01,  2.92936146e-01,  9.72678959e-02,\n",
              "        -4.42875862e-01,  2.93175787e-01, -1.56759262e-01],\n",
              "       [-6.44162819e-02, -3.62672448e-01,  5.48896305e-02,\n",
              "        -4.53648090e-01, -5.12348354e-01, -3.60936159e-03],\n",
              "       [ 3.20020258e-01,  4.68792140e-01, -7.29708523e-02,\n",
              "         1.76933658e+00, -5.21864772e-01,  3.31154156e+00],\n",
              "       [-4.95653152e-01,  1.48870707e+00,  4.12193477e-01,\n",
              "         8.06298542e+00, -1.45915046e-01,  1.16796951e+01],\n",
              "       [ 4.77446020e-02,  4.17308390e-01,  4.02956218e-01,\n",
              "         1.66944468e+00, -4.26614493e-01,  1.87767363e+00],\n",
              "       [-4.09551948e-01,  1.23973382e+00, -4.96427804e-01,\n",
              "         8.39357281e+00,  4.35532033e-01,  1.24588385e+01],\n",
              "       [-3.36310565e-01, -1.82065296e+00, -1.66800588e-01,\n",
              "         5.25254345e+00,  1.42406235e-02,  7.27036858e+00],\n",
              "       [-1.94945365e-01,  6.01975560e-01, -4.90415037e-01,\n",
              "         3.37001681e+00,  1.81621835e-01,  4.90817404e+00],\n",
              "       [-2.36293271e-01,  2.47019872e-01,  2.43130237e-01,\n",
              "         1.20552421e+00, -5.55374064e-02,  1.26812398e+00],\n",
              "       [-4.83381391e-01,  5.74269053e-03,  1.93691730e-01,\n",
              "        -2.54147559e-01,  1.18213100e-02, -6.55414462e-01],\n",
              "       [ 3.63262862e-01,  2.40425253e+00, -3.98889512e-01,\n",
              "         1.24569960e+01, -2.62870640e-01,  1.74254456e+01],\n",
              "       [ 4.19593036e-01,  2.25480899e-01,  1.32096320e-01,\n",
              "         3.44659662e+00, -3.27812225e-01,  4.32268476e+00],\n",
              "       [-2.24509686e-01,  1.48964870e+00,  2.09702998e-01,\n",
              "         3.26906776e+00, -5.30343950e-01,  5.16745949e+00],\n",
              "       [-2.79245228e-01, -6.12571776e-01, -2.03182265e-01,\n",
              "         3.87388802e+00, -3.15326303e-01,  5.30539513e+00]], dtype=float32), array([-2.5437025e-02,  2.2128068e-01, -2.0530623e-01,  1.8654722e+01,\n",
              "       -8.5426904e-02,  2.6809139e+01], dtype=float32), array([[-0.55705255],\n",
              "       [ 3.1300797 ],\n",
              "       [-0.84919965],\n",
              "       [15.899075  ],\n",
              "       [-0.6668146 ],\n",
              "       [22.875147  ]], dtype=float32), array([2.0578485], dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=ListWrapper([178, array([[ 1.16080623e-02,  5.00833765e-02, -4.68697453e-06,\n",
              "        -1.31722761e-03, -5.01408335e-03, -2.09199209e-02,\n",
              "         2.94222739e-02, -1.73321404e-02,  1.37038231e-02,\n",
              "         2.42574941e-02, -3.71169602e-03,  2.31553777e-03,\n",
              "        -3.09107546e-02,  1.34799574e-02,  1.95711851e-02,\n",
              "         8.76585171e-02],\n",
              "       [-1.81113295e-02, -2.90102270e-02,  0.00000000e+00,\n",
              "         9.87165957e-04,  6.49417145e-03, -8.02144315e-03,\n",
              "         3.15394215e-02, -1.00884391e-02, -4.65016719e-03,\n",
              "        -1.97441187e-02, -6.74495299e-04, -1.39645126e-03,\n",
              "        -1.13902315e-02,  1.31237675e-02,  4.51555802e-03,\n",
              "        -1.78922284e-02],\n",
              "       [-9.98140965e-03, -1.33377512e-03, -1.37204304e-04,\n",
              "        -9.14922741e-04,  2.63278242e-02,  5.20174503e-02,\n",
              "        -1.43664079e-02,  5.69878593e-02, -4.10584994e-02,\n",
              "        -2.96181869e-02,  9.60288104e-03, -4.71444009e-03,\n",
              "         7.91734308e-02,  4.53442708e-03, -3.01430523e-02,\n",
              "        -3.52540836e-02],\n",
              "       [-2.35593622e-03,  2.46473327e-02, -4.31189364e-05,\n",
              "        -1.09435921e-03, -4.61074943e-03,  1.60484668e-02,\n",
              "        -1.08705601e-02,  1.88551005e-02,  2.57281214e-03,\n",
              "        -3.03347446e-02, -3.64964386e-03, -1.09064661e-03,\n",
              "         2.45519858e-02,  1.13203237e-02, -4.24692594e-02,\n",
              "         4.42243740e-02],\n",
              "       [-4.45143273e-03,  5.14643965e-03,  0.00000000e+00,\n",
              "        -2.25329446e-03,  1.51148504e-02,  6.09226003e-02,\n",
              "        -1.91918798e-02,  6.28360733e-02, -2.19282042e-02,\n",
              "        -1.92537513e-02,  9.72256006e-04,  1.61336444e-03,\n",
              "         9.33415443e-02, -1.16312392e-02, -2.89042834e-02,\n",
              "         2.21627988e-02],\n",
              "       [-7.42206001e-04,  3.67082618e-02,  0.00000000e+00,\n",
              "        -1.09576991e-04, -4.08719853e-03, -7.77308783e-03,\n",
              "         1.29971253e-02, -8.84496793e-03,  1.45761222e-02,\n",
              "         1.80264171e-02, -2.32991646e-03, -2.78040592e-04,\n",
              "        -1.13200238e-02, -1.73583049e-02, -3.13443430e-02,\n",
              "        -3.71080600e-02],\n",
              "       [-1.54093895e-02, -3.29798758e-02, -2.15594613e-04,\n",
              "         6.33786200e-04,  9.52497299e-04, -1.37991551e-02,\n",
              "        -4.16161446e-03, -1.51433945e-02, -3.62966396e-02,\n",
              "         3.61383967e-02, -2.24764785e-03,  2.76006613e-04,\n",
              "        -2.05671806e-02,  3.36175896e-02,  1.16302660e-02,\n",
              "        -4.27970551e-02],\n",
              "       [ 5.00164693e-03, -2.97098160e-02,  0.00000000e+00,\n",
              "        -1.07526968e-04, -6.74402853e-03, -4.51672189e-02,\n",
              "        -5.01222676e-04, -5.33891097e-02, -1.65589079e-02,\n",
              "        -1.45584932e-02, -4.56111412e-03,  5.39284025e-04,\n",
              "        -6.78403974e-02, -3.61830033e-02, -3.21793072e-02,\n",
              "         5.19100539e-02],\n",
              "       [ 2.03937897e-03,  4.88262856e-03,  0.00000000e+00,\n",
              "         1.71907395e-05, -4.20782808e-03, -4.65572858e-03,\n",
              "        -9.35666822e-03,  4.56781685e-03,  4.31944150e-03,\n",
              "        -6.61434010e-02, -3.41010909e-03,  7.12407462e-04,\n",
              "        -6.78106630e-03, -1.39270425e-02,  1.64976772e-02,\n",
              "        -1.15328683e-02]], dtype=float32), array([-0.00911056, -0.02109892, -0.00021559,  0.00043388, -0.01408657,\n",
              "       -0.07139533, -0.00102244, -0.07280958, -0.03395997, -0.02653712,\n",
              "       -0.01254883,  0.00124966, -0.10650826, -0.03385084, -0.03539567,\n",
              "       -0.03952794], dtype=float32), array([[ 7.6927719e-08, -5.6024477e-05,  2.7444214e-05, -1.7678207e-03,\n",
              "         0.0000000e+00, -2.6990788e-03],\n",
              "       [ 0.0000000e+00, -4.5631040e-04,  0.0000000e+00,  5.6318077e-03,\n",
              "         0.0000000e+00,  6.3122632e-03],\n",
              "       [-3.3713878e-08,  0.0000000e+00, -2.5704503e-08,  7.8603625e-07,\n",
              "         0.0000000e+00,  1.1300668e-06],\n",
              "       [ 1.9838662e-05,  1.2064390e-04, -6.1723542e-05, -1.0490899e-03,\n",
              "         0.0000000e+00, -1.4990655e-03],\n",
              "       [ 0.0000000e+00,  1.6848646e-03,  0.0000000e+00,  2.7498619e-03,\n",
              "         0.0000000e+00,  3.8872273e-03],\n",
              "       [-3.8445371e-05,  1.1712749e-02,  0.0000000e+00,  3.8070621e-03,\n",
              "         2.0171516e-05,  5.1958081e-03],\n",
              "       [-2.3982527e-04,  4.7189193e-03, -4.5297630e-04, -1.2469840e-03,\n",
              "         0.0000000e+00, -1.7921355e-03],\n",
              "       [-4.1164833e-05,  1.2826438e-02,  0.0000000e+00,  4.8129200e-03,\n",
              "         4.4769793e-05,  6.6295862e-03],\n",
              "       [-3.8522444e-04, -1.5423456e-02, -2.2192467e-04, -5.5078561e-03,\n",
              "         0.0000000e+00, -8.4712571e-03],\n",
              "       [ 0.0000000e+00, -3.6623869e-03,  2.3097749e-08, -1.0618615e-02,\n",
              "         0.0000000e+00, -1.5178380e-02],\n",
              "       [ 0.0000000e+00,  7.5711124e-04,  9.0152025e-07,  6.3553496e-05,\n",
              "         5.0938688e-06,  5.6152039e-05],\n",
              "       [-3.9666893e-06, -6.6600885e-05, -1.2643635e-06, -4.6083611e-04,\n",
              "         0.0000000e+00, -6.5103470e-04],\n",
              "       [-5.7915600e-05,  1.7645014e-02,  0.0000000e+00,  5.7869805e-03,\n",
              "         3.1421336e-05,  7.8990115e-03],\n",
              "       [-4.5587911e-04,  3.5014810e-04, -2.0628066e-03,  6.0555730e-03,\n",
              "         0.0000000e+00,  9.7921770e-03],\n",
              "       [ 3.3793972e-06,  7.2658435e-03, -2.2870317e-05, -2.1054128e-02,\n",
              "         0.0000000e+00, -3.0684153e-02],\n",
              "       [ 2.4769604e-04, -3.6510124e-03, -5.1442737e-04, -7.4801492e-03,\n",
              "         1.4344230e-05, -9.3103824e-03]], dtype=float32), array([-2.6060038e-04,  3.4072082e-03, -5.8279163e-04,  7.4787959e-02,\n",
              "        8.3351506e-06,  1.0739555e-01], dtype=float32), array([[ 3.1116753e-04],\n",
              "       [ 2.2867469e-02],\n",
              "       [ 1.7617269e-04],\n",
              "       [-5.1180362e-03],\n",
              "       [-4.1596591e-06],\n",
              "       [-8.3074085e-03]], dtype=float32), array([0.00787497], dtype=float32)]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate"
      ],
      "metadata": {
        "id": "kWHGNcN-VA98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the test data for model evaluation\n",
        "X_test = pd.concat([f[1][0] for f in federated_insurance_data])\n",
        "y_test = pd.concat([f[1][1] for f in federated_insurance_data])\n",
        "\n",
        "test_sets = [tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.convert_to_tensor(np.expand_dims(el[1][0], axis=0)), \n",
        "    tf.convert_to_tensor(np.expand_dims(el[1][1], axis=0)))) \n",
        "    for el in federated_insurance_data]"
      ],
      "metadata": {
        "id": "1qAVD1haVA9-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "evaluation = tff.learning.build_federated_evaluation(model_fn_5_mod)\n",
        "# print(evaluation.type_signature.formatted_representation())\n",
        "model_weights = iterative_process.get_model_weights(state)\n",
        "train_metrics = evaluation(model_weights, test_sets)\n",
        "train_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f27284-a319-4ed9-ffe6-7e04db33adb8",
        "id": "xHTiYD-nVA9_"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-fe93b6610415>:2: DeprecationWarning: `tff.learning.build_federated_evaluation` is deprecated, use `tff.learning.algorithms.build_fed_eval` instead.\n",
            "  evaluation = tff.learning.build_federated_evaluation(model_fn_5_mod)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('eval',\n",
              "              OrderedDict([('mean_absolute_error', nan),\n",
              "                           ('loss', 0.0),\n",
              "                           ('num_examples', 0),\n",
              "                           ('num_batches', 3)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2scr = RSquare\n"
      ],
      "metadata": {
        "id": "-NKLXp9aiDqA"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model from training results and evaluate\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "model = create_keras_model(input_features = 9)\n",
        "model_weights.assign_weights_to(model)\n",
        "model.compile(\n",
        "    loss=tf.losses.mae,\n",
        "    optimizer=tf.optimizers.SGD(),\n",
        "    metrics=[\"mae\", 'mean_squared_error'#, r2_score\n",
        "             ]\n",
        ")\n",
        "\n",
        "# The evaluation results, for technical reasons the metrics_names is called afterwards. However, its order fits to the results\n",
        "print(model.evaluate(X_test, y_test))\n",
        "print(model.metrics_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f5c583-502f-4de7-f0cf-672b62489be2",
        "id": "ob4g5OHuVA-A"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 7ms/step - loss: 10782.5020 - mae: 10782.5020 - mean_squared_error: 264664192.0000\n",
            "[10782.501953125, 10782.501953125, 264664192.0]\n",
            "['loss', 'mae', 'mean_squared_error']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "q_9XHZx0XddY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- the original repo uses a totally different model as in centralized learning.\n",
        "  - linear\n",
        "  - no learning by zero initializer\n",
        "- new learner cuts mae ~66%\n",
        "- how to calculate RSquare?\n",
        "- error: no learning occurs (for clients). Empty?\n"
      ],
      "metadata": {
        "id": "mI5W1ESJXe4z"
      }
    }
  ]
}